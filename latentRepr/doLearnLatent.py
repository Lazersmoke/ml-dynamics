import os
# Tell tensorflow not to use the GPU
#os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
# Tone down warning messages
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'

print("Loading TensorFlow...")
import tensorflow as tf

from tensorflow.keras.layers import Reshape, Dense, Flatten, Conv2D, Conv2DTranspose, Dropout, MaxPooling2D, UpSampling2D
from tensorflow.keras import Model
#import ccnn_layers

import random
import numpy as np
import scipy.io as sio
import matplotlib.pyplot as plt
plt.rc('image', cmap='inferno')

import matplotlib.ticker as mplticker

from scipy import ndimage, misc, signal, stats

### Settings ###
EPOCHS = 1000

batchSize = 64

### /Settings ###

# Import training data from MATLAB file
# Generated by makeStraems.m
fname = "../trainingData1000.mat"
print("Reading " + fname + " ...")
trainingData = sio.loadmat(fname)
examples = tf.cast(trainingData['vortOuts'],tf.float32)

spaceSize = examples.shape[-1]
spaceCenter = spaceSize // 2

data_frameTime = trainingData['timeBetweenFrames'][0,0]
data_npu = trainingData['npu'][0,0]
data_dissipations = trainingData['dissipations']
chargeCount = np.squeeze(trainingData['chargeCount'])
plt.plot(data_dissipations)
plt.show(block=True)

print(
  f'Training data metadata:\n'
  f'  frameTime: {data_frameTime}\n'
  f'  npu: {data_npu}\n'
  f'  numDataPoints: {examples.shape[0]}\n'
  )

forcingWiggle = np.fromfunction(lambda x,y: y + 2 * np.sin(4 * 2 * np.math.pi/128 * x),[128,128])
def visualize(original,reconstructed,latent,lab="",epc=""):
  vizLatent(reconstructed,latent,lab,epc)
  vizReal(original,reconstructed,lab,epc)

def vizLatent(reconstructed,latent,lab="",epc=""):
  # Latent plot
  f, (ax1,ax2) = plt.subplots(1, 2,figsize=(20,10))
  ax1.set_title("Vorticity")
  ax1.contourf(reconstructed,cmap="cividis",levels=40)

  ax2.set_title("Latent representation, epoch #" + epc)
  embedDimension = latent.shape[0]
  edgeSize = np.floor(np.sqrt(embedDimension)).astype('int32')
  while (np.mod(embedDimension,edgeSize) > 0):
    edgeSize = edgeSize - 1
  ax2.xaxis.set_major_locator(mplticker.MaxNLocator(integer=True))
  ax2.yaxis.set_major_locator(mplticker.MaxNLocator(integer=True))
  f.colorbar(ax2.imshow(np.reshape(latent,[edgeSize,embedDimension // edgeSize]),cmap="binary"),ax=ax2)

  f.savefig("images/latent" + lab + ".png", bbox_inches='tight')
  plt.close(f)

def vizReal(original,reconstructed,lab="",epc="",direc="images"):
  # Real space plot
  f, (ax1) = plt.subplots(1, 1,figsize=(10,10),dpi=150)
  
  lossAmt = lossFn(original,reconstructed)
  ax1.set_title("Reconstructed vs Original (" + lab + "), loss = " + str(lossAmt.numpy()) + ", epoch #" + epc)

  ax1.contourf(original,cmap="gray",levels=40)

  ax1.contour(forcingWiggle,colors='green',alpha=0.05,levels=16)
  ax1.contour(reconstructed,cmap="plasma",levels=30)

  f.savefig(direc + "/reconstruction" + lab + ".png", bbox_inches='tight')
  plt.close(f)

  original.numpy().astype('float32').tofile("dumps/original" + lab + '.dat')
  reconstructed.numpy().astype('float32').tofile("dumps/recovered" + lab + '.dat')

print("Data shape: ",examples.shape)

whole_ds = tf.data.Dataset.from_tensor_slices(examples).shuffle(10000).batch(batchSize)
train_ds = whole_ds.shard(2,0)
test_ds = whole_ds.shard(2,1)

class LatentModel(Model):
  def __init__(self):
    super(LatentModel, self).__init__()
    self.inp = tf.keras.layers.InputLayer(input_shape=(batchSize,128,128,1))
    self.mp = MaxPooling2D((2,2))
    self.c1 = Conv2D(32,8,activation='relu')
    self.c2 = Conv2D(32,8,activation='relu')
    self.c3 = Conv2D(32,4,activation='relu')
    self.c4 = Conv2D(64,4,activation='relu')
    self.c5 = Conv2D(128,2,activation='relu')

    self.flat = Flatten()

    self.embedDimension = 32
    self.dIn = Dense(self.embedDimension,activation='relu')
    self.drop = Dropout(0.2)
    self.dOut = Dense(128,activation='relu')
    self.rshp = Reshape(target_shape=[4,4,8])

    self.up = UpSampling2D((2,2))
    self.dc5 = Conv2DTranspose(128,(2,2),activation='relu')
    self.dc4 = Conv2DTranspose(64,(4,4),activation='relu')
    self.dc3 = Conv2DTranspose(32,(4,4),activation='relu')
    self.dc2 = Conv2DTranspose(16,(8,8),activation='relu')
    self.dc1 = Conv2DTranspose(1,(8,8))

  def encode(self, x):
    x = tf.expand_dims(x,axis=-1)
    x = self.c1(x)
    x = self.mp(x)

    x = self.c2(x)
    x = self.mp(x)

    x = self.c3(x)
    x = self.mp(x)

    x = self.c4(x)
    x = self.mp(x)

    x = self.c5(x)
    x = self.mp(x)

    x = self.flat(x)
    x = self.dIn(x)

    return x

  def decode(self, x):
    x = self.dOut(x)
    x = self.rshp(x)

    x = self.dc5(x)
    x = self.up(x)

    x = self.dc4(x)
    x = self.up(x)

    x = self.dc3(x)
    x = self.up(x)

    x = self.dc2(x)
    x = self.up(x)

    x = self.dc1(x)
    x = tf.image.crop_to_bounding_box(x,5,5,128, 128)
    return tf.squeeze(x)

  def call(self, x):
    x = self.encode(x)
    x = self.drop(x) # Prevents overfitting
    return self.decode(x)

  def getEigs(self):
    oneHots = tf.eye(self.embedDimension)
    return decode(oneHots)

model = LatentModel()

def lossFn(original,reconstructed):
  errors = original - reconstructed
  sqErrs = tf.math.log(tf.math.cosh(errors))
  return tf.math.reduce_mean(sqErrs,axis = (-1,-2))

def symmetryDither(psi):
  rollAmt = np.random.randint(128)
  psi = tf.roll(psi,rollAmt,axis=-1) # Continuous x-translation

  stepsDiscrete = np.random.randint(8)
  for i in range(stepsDiscrete):
    psi = -tf.reverse(tf.roll(psi,128 // 8,axis = -2),axis=[-1])

  doParity = np.random.randint(2)
  if doParity > 0:
    psi = tf.reverse(psi,axis = [-1,-2])
  return psi

testOmega = examples[np.random.randint(examples.shape[0])]
for i in range(20):
  dithered = symmetryDither(testOmega)
  vizReal(testOmega,dithered,"dither" + str(i),"-",direc="dither")

optimizer = tf.keras.optimizers.Adam()

train_loss = tf.keras.metrics.Mean(name='train_loss')

test_loss = tf.keras.metrics.Mean(name='test_loss')

@tf.function
def train_step(original):
  # GradientTape keeps track of gradients so we can backprop
  symOrig = symmetryDither(original)
  with tf.GradientTape() as tape:
    reconstructed = model(symOrig, training=True)
    loss = lossFn(symOrig, reconstructed)
  gradients = tape.gradient(loss, model.trainable_variables)
  optimizer.apply_gradients(zip(gradients, model.trainable_variables))

  train_loss(loss)

@tf.function
def test_step(original):
  # training=False disables Dropout layer
  reconstructed = model(original, training=False)
  t_loss = lossFn(original, reconstructed)

  test_loss(t_loss)

checkpoint_path = "training_data/cp-{epoch:04d}.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)

# Save the epoch zero weights to ensure the folder is populated
if not os.path.isdir(checkpoint_dir):
  model.save_weights(checkpoint_path.format(epoch=0))

latest = tf.train.latest_checkpoint(checkpoint_dir)
model.load_weights(latest)

for epoch in range(EPOCHS):
  # Reset the metrics at the start of the next epoch
  train_loss.reset_states()
  test_loss.reset_states()

  for original in train_ds:
    # Progess bar
    print(".",end="",flush=True)
    train_step(original)

  print()

  # How many examples to output as graphs every vizEpochs
  n = 8
  vizEpochs = 10
  vized = False
  for test_orig in test_ds:
    print("'",end="",flush=True)
    test_step(test_orig)
    # Also vizualize on last epoch
    if not vized and ((epoch % vizEpochs == 0) or (epoch == EPOCHS - 1)):
      symOrig = symmetryDither(test_orig)
      recovered = model(symOrig,training=False)
      latent = model.encode(symOrig)
      oneHots = tf.eye(model.embedDimension)
      eigs = model.decode(oneHots)
      for l in range(eigs.shape[0]):
        vizLatent(eigs[l],oneHots[l],"Eigen " + str(l),str(epoch))
      vized = True
      print("\b\"",end="",flush=True)
      for k in range(n):
        # If this is a truncated epoch, don't crash
        if k < len(test_orig):
          # Save the weights every time we visualize anything, so we can always get that network back
          model.save_weights(checkpoint_path.format(epoch=epoch))
          visualize(symOrig[k],recovered[k],latent[k],str(k),str(epoch))
  print()
  print(
    f'Epoch {epoch}, '
    f'Reconstruction Loss: {train_loss.result()}, '
    f'Test Reconstruction Loss: {test_loss.result()}'
  )

# Still save weights even if n=0 graphs
model.save_weights(checkpoint_path.format(epoch=EPOCHS))
